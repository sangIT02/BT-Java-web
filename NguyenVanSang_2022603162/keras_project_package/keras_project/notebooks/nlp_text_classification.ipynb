{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f27a82",
   "metadata": {},
   "source": [
    "# NLP â€“ Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a61b065",
   "metadata": {},
   "source": [
    "# ðŸ—£ï¸ NLP â€“ Text Classification (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7b193",
   "metadata": {},
   "source": [
    "## Dá»¯ liá»‡u: ../data/nlp_texts.csv (hoáº·c trong Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fa86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tensorflow keras pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f3e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "drive_path = '/content/drive/MyDrive/keras_project/data/nlp_texts.csv'\n",
    "path = drive_path if tf.io.gfile.exists(drive_path) else '../data/nlp_texts.csv'\n",
    "df = pd.read_csv(path)\n",
    "texts = df['text'].astype(str).tolist()\n",
    "labels = df['label'].values.astype('float32')\n",
    "\n",
    "max_tokens=5000; max_len=50\n",
    "vec = layers.TextVectorization(max_tokens=max_tokens, output_sequence_length=max_len)\n",
    "vec.adapt(tf.data.Dataset.from_tensor_slices(texts).batch(32))\n",
    "\n",
    "X = vec(np.array([[t] for t in texts])); y = labels\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Embedding(max_tokens, 64, input_length=max_len),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "hist = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=8, batch_size=32)\n",
    "\n",
    "plt.figure(); plt.plot(hist.history['accuracy'], label='acc'); plt.plot(hist.history['val_accuracy'], label='val_acc'); plt.legend(); plt.title('Accuracy'); plt.xlabel('epoch'); plt.show()\n",
    "samples = ['Keras training is great', 'This model is terrible']\n",
    "Xs = vec(np.array([[t] for t in samples])); probs = model.predict(Xs).squeeze()\n",
    "for s,p in zip(samples, probs): print(s, '->', float(p))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
